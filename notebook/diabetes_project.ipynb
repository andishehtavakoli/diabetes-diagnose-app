{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5a613e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "from loguru import logger\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c84e67",
   "metadata": {},
   "source": [
    "## Multi Function ML End to End Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49dd5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(file_path):\n",
    "    try:        \n",
    "        df = pd.read_csv(file_path)\n",
    "        logger.info(df.head(2))\n",
    "        logger.info('Dataframe read!')\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "def detect_anomalies(data, threshold=3.5):\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    z_scores = (data - mean) / std\n",
    "    return np.abs(z_scores) > threshold\n",
    "\n",
    "\n",
    "def clean_df(df):\n",
    "    \n",
    "    # remove duplicate\n",
    "    logger.info(f'Number of duplicates before drop duplicate : {df.duplicated().shape[0]}')\n",
    "    df.drop_duplicates().reset_index(inplace=True, drop=True)\n",
    "    logger.info(f'Number of duplicates after drop duplicate : {df.duplicated().shape[0]}')\n",
    "    \n",
    "    # change the types\n",
    "    df[['gender', 'smoking_history']] = df[['gender', 'smoking_history']].astype('category')\n",
    "    df['age'] = df['age'].astype('int')\n",
    "    \n",
    "    # remove NaN\n",
    "    logger.info(f'Number of NaN before remove: {df.isna().sum()}')\n",
    "    df.dropna().reset_index(inplace=True, drop=True)\n",
    "    logger.info(f'Number of NaN after remove: {df.isna().sum()}')\n",
    "    \n",
    "    # remove outlier\n",
    "    mask_bmi = detect_anomalies(df['bmi'], threshold=3.5)\n",
    "    df = df[~mask_bmi]\n",
    "\n",
    "    mask_glucose_level = detect_anomalies(df['blood_glucose_level'], threshold=3.5)\n",
    "    df = df[~mask_glucose_level]\n",
    "    logger.info('outliers in bmi and blood glucose level is removed!')    \n",
    "    \n",
    "    return df\n",
    "      \n",
    "    \n",
    "def preprocess_df(df, feature_selection, target_var):\n",
    "    \"\"\"\n",
    "    Split dataframe into X and y, and train and test consecutively. Then impute and scale both train and test features.\n",
    "    Returns the train and test sets.\n",
    "    \"\"\"\n",
    "    X = df[feature_selection]\n",
    "    y = df[target_var]\n",
    "    \n",
    "    num_features = list(X.select_dtypes(include='number').columns)\n",
    "    cat_features = list(X.select_dtypes(exclude='number').columns)\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(), cat_features),\n",
    "        ('num', StandardScaler(), num_features)\n",
    "    ])\n",
    "\n",
    "    # Split X, y\n",
    "\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)\n",
    "\n",
    "    # Preprocess the features for both train and test sets\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def model_training(model, x_train, y_train):\n",
    "                  \n",
    "    return model.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "def predict_and_evaluate(model, x_test, y_test, return_data=True):\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_name = type(model).__name__\n",
    "    \n",
    "    metric_df = pd.DataFrame([{\n",
    "            'model_name': model_name,\n",
    "            'f1' : f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'accuracy': accuracy    \n",
    "        }])\n",
    "    \n",
    "    if return_data: \n",
    "        \n",
    "        return metric_df.style.background_gradient(cmap='coolwarm')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return metric_df.drop(columns=['model_name']).to_dict(orient='records')[0]\n",
    "    \n",
    "def train_classification_model(params_dict, metrics_dict, model, experiment_name='Default'):\n",
    "\n",
    "    # Start an MLflow run\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        # Log metrics and parameters with MLflow\n",
    "        mlflow.log_params(params_dict)\n",
    "        mlflow.log_metrics(metrics_dict)\n",
    "\n",
    "        # Save the model as an artifact\n",
    "        mlflow.sklearn.log_model(model, type(model).__name__)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3581355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 16:25:38.608 | INFO     | __main__:load_df:4 -    gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
      "0  Female  80.0             0              1           never  25.19   \n",
      "1  Female  54.0             0              0         No Info  27.32   \n",
      "\n",
      "   HbA1c_level  blood_glucose_level  diabetes  \n",
      "0          6.6                  140         0  \n",
      "1          6.6                   80         0  \n",
      "2023-08-01 16:25:38.615 | INFO     | __main__:load_df:5 - Dataframe read!\n",
      "2023-08-01 16:25:38.681 | INFO     | __main__:clean_df:15 - Number of duplicates before drop duplicate : 100000\n",
      "2023-08-01 16:25:38.792 | INFO     | __main__:clean_df:17 - Number of duplicates after drop duplicate : 100000\n",
      "2023-08-01 16:25:38.841 | INFO     | __main__:clean_df:24 - Number of NaN before remove: gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n",
      "2023-08-01 16:25:38.881 | INFO     | __main__:clean_df:26 - Number of NaN after remove: gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n",
      "2023-08-01 16:25:38.917 | INFO     | __main__:clean_df:34 - outliers in bmi and blood glucose level is removed!\n"
     ]
    }
   ],
   "source": [
    "df = load_df('diabetes_prediction_dataset.csv')\n",
    "df= clean_df(df)\n",
    "X_train, X_test, y_train, y_test = preprocess_df(df, df.drop(columns=['diabetes']).columns, 'diabetes')\n",
    "trained_model = model_training(KNeighborsClassifier(), X_train, y_train)\n",
    "metrics = predict_and_evaluate(trained_model, X_test, y_test, return_data=False)\n",
    "params = trained_model.get_params()\n",
    "train_classification_model(params, metrics, trained_model, experiment_name='Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "13ee841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-01 16:27:29 -0700] [16968] [INFO] Starting gunicorn 20.1.0\n",
      "[2023-08-01 16:27:29 -0700] [16968] [INFO] Listening at: http://127.0.0.1:5000 (16968)\n",
      "[2023-08-01 16:27:29 -0700] [16968] [INFO] Using worker: sync\n",
      "[2023-08-01 16:27:29 -0700] [16969] [INFO] Booting worker with pid: 16969\n",
      "[2023-08-01 16:27:29 -0700] [16970] [INFO] Booting worker with pid: 16970\n",
      "[2023-08-01 16:27:29 -0700] [16971] [INFO] Booting worker with pid: 16971\n",
      "[2023-08-01 16:27:29 -0700] [16972] [INFO] Booting worker with pid: 16972\n",
      "^C\n",
      "[2023-08-01 16:29:18 -0700] [16968] [INFO] Handling signal: int\n",
      "[2023-08-01 16:29:18 -0700] [16970] [INFO] Worker exiting (pid: 16970)\n",
      "[2023-08-01 16:29:18 -0700] [16969] [INFO] Worker exiting (pid: 16969)\n",
      "[2023-08-01 16:29:18 -0700] [16971] [INFO] Worker exiting (pid: 16971)\n",
      "[2023-08-01 16:29:18 -0700] [16972] [INFO] Worker exiting (pid: 16972)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
